[["multiple-regression-models.html", "2 multiple regression models", " 2 multiple regression models usbeer &lt;- read.csv(&quot;/cloud/project/data/beernew.txt&quot;) attach(usbeer) head(usbeer) ## year month time beer c348 s348 c432 s432 ## 1 1987 1 1 15.601 -0.57757270 0.8163393 -0.9101060 0.4143756 ## 2 1987 2 2 15.633 -0.33281954 -0.9429905 0.6565858 -0.7542514 ## 3 1987 3 3 17.656 0.96202767 0.2729519 -0.2850193 0.9585218 ## 4 1987 4 4 17.422 -0.77846230 0.6276914 -0.1377903 -0.9904614 ## 5 1987 5 5 17.436 -0.06279052 -0.9980267 0.5358268 0.8443279 ## 6 1987 6 6 18.584 0.85099448 0.5251746 -0.8375280 -0.5463943 2.0.1 additivie decomposition model with a fourth-degree polynomial trend Seasonal indices add to 0 for all t. \\[ \\begin{equation} y_t = \\beta_0 + \\beta_2t^2 + \\beta_3t^3 + \\beta_4t^4 + S_t + \\epsilon_t \\end{equation} \\] R creates dummies. fmonth&lt;-as.factor(month) levels(fmonth) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; &quot;11&quot; &quot;12&quot; class(time) ## [1] &quot;integer&quot; time &lt;- as.numeric(time) class(time) ## [1] &quot;numeric&quot; model1&lt;- lm(beer~time+I(time^2)+I(time^3)+I(time^4)+fmonth);summary(model1) ## ## Call: ## lm(formula = beer ~ time + I(time^2) + I(time^3) + I(time^4) + ## fmonth) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.33863 -0.26965 0.01012 0.25978 1.52952 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.556e+01 1.390e-01 111.933 &lt; 2e-16 *** ## time 1.523e-02 4.350e-03 3.502 0.000521 *** ## I(time^2) -1.675e-04 4.732e-05 -3.540 0.000453 *** ## I(time^3) 6.496e-07 1.905e-07 3.410 0.000723 *** ## I(time^4) -8.780e-10 2.533e-10 -3.466 0.000594 *** ## fmonth2 -6.423e-01 1.132e-01 -5.676 2.87e-08 *** ## fmonth3 1.579e+00 1.132e-01 13.950 &lt; 2e-16 *** ## fmonth4 1.447e+00 1.132e-01 12.786 &lt; 2e-16 *** ## fmonth5 2.595e+00 1.132e-01 22.930 &lt; 2e-16 *** ## fmonth6 2.862e+00 1.132e-01 25.289 &lt; 2e-16 *** ## fmonth7 2.363e+00 1.132e-01 20.874 &lt; 2e-16 *** ## fmonth8 1.950e+00 1.132e-01 17.223 &lt; 2e-16 *** ## fmonth9 2.838e-01 1.132e-01 2.507 0.012627 * ## fmonth10 9.398e-03 1.132e-01 0.083 0.933896 ## fmonth11 -1.264e+00 1.132e-01 -11.161 &lt; 2e-16 *** ## fmonth12 -1.700e+00 1.133e-01 -15.013 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4455 on 356 degrees of freedom ## Multiple R-squared: 0.9237, Adjusted R-squared: 0.9204 ## F-statistic: 287.2 on 15 and 356 DF, p-value: &lt; 2.2e-16 examine residuals plot(ts(resid(model1),start=c(1987,1),freq=12),xlab=&quot;time&quot;,ylab=&quot;residu als&quot;,main=&quot;Residuals of Model 1&quot;) normal quantile plot of residuals. tails are a bit long relative to normaility. But not much of a problem. Null of Shapiro Wilk is normality of residuals qqnorm(resid(model1)) qqline(resid(model1)) shapiro.test(resid(model1)) ## ## Shapiro-Wilk normality test ## ## data: resid(model1) ## W = 0.99333, p-value = 0.09881 Calculate and interpret estimated seasonal indices from the model. Selects estimated intercpet coefficients and the estimated coefficients for the fmonth dummies, then calculates the seasonal index estimates from these. In June, production is 2.072 million barrels above the level of the trendsâ€¦ b1&lt;-coef(model1)[1] b2&lt;-coef(model1)[6:16]+b1 b3&lt;-c(b1,b2) seas&lt;-b3-mean(b3) seas ## (Intercept) fmonth2 fmonth3 fmonth4 fmonth5 fmonth6 ## -0.7902230 -1.4325268 0.7884912 0.6568310 1.8049441 2.0721854 ## fmonth7 fmonth8 fmonth9 fmonth10 fmonth11 fmonth12 ## 1.5725549 1.1594398 -0.5064181 -0.7808250 -2.0540390 -2.4904147 Variable seas to time series clas sand plot indices seas.ts&lt;-ts(seas) plot(seas.ts,ylab=&quot;seasonal indices&quot;,xlab=&quot;month&quot;) Partial F tests and hypothesis. Partial F test tests the null that some of the regression coefficients are simultaneously 0. Fir two models, one with all regressers, and a reduces. In the latter, omit variables corresponding to the parameters which are hypothesized to be 0. Suppose T is number of observations. The F stat for the partial F test can be calculated from the R squared of the two models. The F statistic is: \\[ \\begin{equation} F_{r,T-k-1} = \\frac{((R^2(full)-R^2(reduced))/r}{(1-R^2(full))/(T-k-1)} \\end{equation} \\] where numerator DF = r and T-k-1 denominator degrees of freedom. Reject null if partial F is large (p value small). model2&lt;-lm(beer~time+I(time^2)+I(time^3)+I(time^4)) summary(model2) ## ## Call: ## lm(formula = beer ~ time + I(time^2) + I(time^3) + I(time^4)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.4602 -1.1566 0.1497 1.3892 3.0871 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.643e+01 4.099e-01 40.077 &lt;2e-16 *** ## time 1.386e-02 1.518e-02 0.913 0.362 ## I(time^2) -1.643e-04 1.652e-04 -0.994 0.321 ## I(time^3) 6.708e-07 6.651e-07 1.008 0.314 ## I(time^4) -9.418e-10 8.846e-10 -1.065 0.288 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.556 on 367 degrees of freedom ## Multiple R-squared: 0.04045, Adjusted R-squared: 0.02999 ## F-statistic: 3.867 on 4 and 367 DF, p-value: 0.004317 summary(model1)$r.squared ## [1] 0.9236588 summary(model2)$r.squared ## [1] 0.04044511 \\[ \\begin{equation} F_{11,356} = \\frac{((0.92366-0.04045)/11}{(1-0.92366)/(356)} = 374.43 \\end{equation} \\] confirm with test anova(model2,model1) ## Analysis of Variance Table ## ## Model 1: beer ~ time + I(time^2) + I(time^3) + I(time^4) ## Model 2: beer ~ time + I(time^2) + I(time^3) + I(time^4) + fmonth ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 367 888.27 ## 2 356 70.67 11 817.6 374.42 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Do residuals suggest that the model disturbance term forms an uncorrelated sequence? Measure lag 1 correlation of the residuals, correlation between residuals which are directly adjacent in time. Lag one correlation not significant. r&lt;-resid(model1)[2:372] r1&lt;-resid(model1)[1:371] cor.test(r,r1) ## ## Pearson&#39;s product-moment correlation ## ## data: r and r1 ## t = 1.4767, df = 369, p-value = 0.1406 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.02536446 0.17708380 ## sample estimates: ## cor ## 0.07664964 Autocorrelation structure of residuals by estimates of the correlations at multiple lags. See significant residual correlations at many lags (significance is indicates by extention beyond the blue dashed lines). acf(ts(resid(model1)),36) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
